- front: 'Binary Search'
  back: |
    def binary_search(arr, target):
        l, r = 0, len(arr) - 1
        
        while l <= r:
            m = l + (r - l) // 2
            
            if arr[m] > target:
                r = m - 1
            elif arr[m] < target:
                l = m + 1
            else:
                return m
        
        return -1
  time-complexity: O(log n)
  space-complexity: O(1)
  description: |
    Paradigms:
      - Divide and Conquer

- front: 'Trie: Insert Word'
  back: |
    def insert_word(word):
        ptr = self.root
        for letter in word:
            ptr = ptr.children.setdefault(letter, TrieNode())
        ptr.final_node = True
  time-complexity: O(n), where n is the length of the word.
  space-complexity: O(n) for a single word, where n is the word's length.
  description: |
    Paradigms:
      - Tree-Based Search
      - Prefix Tree
      - Trie

- front: 'Trie: Search Word'
  back: |
    def search_word(word) -> bool:
        ptr = self.root
        for letter in word:
            if letter not in ptr.children:
                return False
            ptr = ptr.children[letter]
        return ptr.final_node
  time-complexity: O(n), where n is the length of the word.
  space-complexity: O(1) for a single word, where n is the word's length.
  description: |
    Paradigms:
      - Tree-Based Search
      - Prefix Tree
      - Trie

- front: 'Trie: Search Prefix'
  back: |
    def search_prefix(prefix) -> bool:
        ptr = self.root
        for letter in prefix:
            if letter not in ptr.children:
                return False
            ptr = ptr.children[letter]
        return True
  time-complexity: O(n), where n is the length of the prefix.
  space-complexity: O(1) for a single word, where n is the word's length.
  description: |
    Paradigms:
      - Tree-Based Search
      - Prefix Tree
      - Trie

- front: 'Trie: Delete Word'
  back: |
    def delete_word(word):
        def _delete(ptr, word, index) -> bool:
            if index == len(word):
                if not ptr.final_node:
                    return False
                ptr.final_node = False
                return len(ptr.children) == 0  # If no children, delete.
            letter = word[index]
            if letter not in ptr.children:
                return False
            deletable = _delete(ptr.children[letter], word, index + 1)
            if deletable:
                del ptr.children[letter]
                return len(ptr.children) == 0 and not ptr.final_node
            return False
        
        _delete(self.root, word, 0)
  time-complexity: O(n), where n is the length of the word.
  space-complexity: O(h), where h is the height of the tree (due to recursion stack)
  description: |
    Paradigms:
      - Tree-Based Search
      - Prefix Tree
      - Trie

- front: 'Trie: Autocomplete'
  back: |
    def autocomplete(prefix) -> list:
        ptr = self.root
        for letter in prefix:
            if letter not in ptr.children:
                return []  # No words with this prefix
            ptr = ptr.children[letter]

        # Perform DFS to collect all words from this ptr onward
        def dfs(ptr, current_word):
            matches = []
            if ptr.final_node:
                matches.append(current_word)
            for letter, child_node in ptr.children.items():
                matches.extend(dfs(child_node, current_word + letter))
            return matches

        return dfs(ptr, prefix)
  time-complexity: O(m), where m is the number of words starting with the
  space-complexity: O(n) for a single word, where n is the word's length.
  description: |
    Paradigms:
      - Tree-Based Search
      - Prefix Tree
      - Trie

- front: 'Singly-Linked List: Insert at the head'
  back: |
    def insert_at_head(head, val) -> ListNode:
        new_node = ListNode(val)
        if not head:
            return new_node
        new_node.next = head
        return new_node
  time-complexity: O(1), constant time.
  space-complexity: O(1).
  description: |
    Paradigms:
      - Linear Data Structures
      - Pointer Manipulation
      - Linked List

- front: 'Singly-Linked List: Insert at the Tail'
  back: |
    def insert_at_tail(head, val) -> ListNode:
        new_node = ListNode(val)
        if not head:
            return new_node
        ptr = head
        while ptr.next:
            ptr = ptr.next
        ptr.next = new_node
        return head
  time-complexity: O(n), where n is the number of nodes.
  space-complexity: O(1).
  description: |
    Paradigms:
      - Linear Data Structures
      - Pointer Manipulation
      - Linked List

- front: 'Singly-Linked List: Delete Node'
  back: |
    def delete_node(head, val) -> ListNode:
        if head.val == val:
            return head.next
        ptr = head
        while ptr and ptr.next:
            if ptr.next.val == val:
                ptr.next = ptr.next.next
                break
            ptr = ptr.next
        return head
  time-complexity: O(n), where n is the number of nodes.
  space-complexity: O(1).
  description: |
    Paradigms:
      - Linear Data Structures
      - Pointer Manipulation
      - Linked List

- front: 'Singly-Linked List: Insert at index'
  back: |
    def insert_at_index(head, index, val) -> ListNode:
        if index < 0:
            return head
        new_node = ListNode(val)
        if index == 0:
            new_node.next = head
            return new_node
        ptr = head
        for i in range(index - 1):
            if not ptr:
                return head
            ptr = ptr.next
        if ptr:
            new_node.next = ptr.next
            ptr.next = new_node
        return head
  time-complexity: O(n), where n is the number of nodes.
  space-complexity: O(1).
  description: |
    Paradigms:
      - Linear Data Structures
      - Pointer Manipulation
      - Linked List

- front: 'Singly-Linked List: Delete at index'
  back: |
    def delete_at_index(head, index) -> ListNode:
        if not head or index < 0:
            return head
        if index == 0:
            return head.next
        ptr = head
        for i in range(index - 1):
            if not ptr:
                return head
            ptr = ptr.next
        if ptr and ptr.next:
            ptr.next = ptr.next.next
        return head
  time-complexity: O(n), where n is the number of nodes.
  space-complexity: O(1).
  description: |
    Paradigms:
      - Linear Data Structures
      - Pointer Manipulation
      - Linked List

- front: 'Singly-Linked List: Merge sorted list'
  back: |
    def merge_sorted_lists(l1, l2) -> ListNode:
        dummy = ListNode()
        ptr = dummy
        while l1 and l2:
            if l1.val < l2.val:
                ptr.next = l1
                l1 = l1.next
            else:
                ptr.next = l2
                l2 = l2.next
            ptr = ptr.next
        ptr.next = l1 if l1 else l2
        return dummy.next
  time-complexity: O(n + m), where n and m are the lengths of the two lists.
  space-complexity: O(1) for all operations except reverse_list.
  description: |
    Paradigms:
      - Linear Data Structures
      - Pointer Manipulation
      - Linked List

- front: 'Singly-Linked List: Reverse List'
  back: |
    def reverse_list(head) -> ListNode:
        l = None
        m = head
        r = None

        while m:
            r = m.next
            m.next = l
            l = m
            m = r
        
        return l
  time-complexity: O(n), where n is the number of nodes.
  space-complexity: O(1).
  description: |
    Paradigms:
      - Linear Data Structures
      - Pointer Manipulation
      - Linked List

- front: 'Singly-Linked List: Detect cycle'
  back: |
    def detect_cycle(head) -> bool:
        sptr = head
        fptr = head
        
        while fptr and fptr.next:
            sptr = sptr.next
            fptr = fptr.next.next
            if sptr == fptr:
                return True
        return False
  time-complexity: O(n), where n is the number of nodes.
  space-complexity: O(1).
  description: |
    Paradigms:
      - Linear Data Structures
      - Pointer Manipulation
      - Linked List

- front: 'Breadth First Search (Graph)'
  back: |
    from collections import deque

    def bfs(graph, start_vertex):
        visited = set()
        que = deque([start_vertex])

        while que:
            vertex = que.popleft()
            if vertex not in visited:
                print(vertex)
                que.extend(graph.get(vertex, []))
                visited.add(vertex)
  time-complexity: O(V + E), where V is the number of vertices and E is the number of edges.
  space-complexity: O(V), space for visited nodes and the queue.
  description: |
    Use Cases:
      - Find shortest path in unweighted graphs.
      - Find all reachable nodes from a source node.
    Paradigms:
      - Graph Traversal
      - Queue-Based Search
      - FIFO

- front: 'Depth First Search: Iterative (Graph)'
  back: |
    def dfs(graph, start_vertex):
        visited = set()
        stack = [start_vertex]

        while stack:
            vertex = stack.pop()
            if vertex not in visited:
                print(vertex)
                visited.add(vertex)
                stack.extend(graph.get(vertex, []))
  time-complexity: O(V + E), where V is the number of vertices and E is the number of edges.
  space-complexity: O(V), space for visited nodes and the stack.
  description: |
    Use Cases:
      - Find connected components.
      - Traversal for exploring all nodes.
    Paradigms:
      - Graph Traversal
      - Stack-Based Search
      - LIFO

- front: 'Depth First Search: Recursive (Graph)'
  back: |
    def dfs(graph, start_vertex, visited = None):
        if visited is None:
            visited = set()
        visited.add(start_vertex)
        print(start_vertex)

        for neighbor in graph.get(start_vertex, []):
            if neighbor not in visited:
                dfs(graph, neighbor, visited)
  time-complexity: O(V + E), where V is the number of vertices and E is the number of edges.
  space-complexity: O(V), due to the recursion stack.
  description: |
    Use Cases: 
      - Explore all nodes in a graph recursively.
    Paradigms:
      - Graph traversal
      - Recursion

- front: 'Dijkstra’s Algorithm (Shortest Path)'
  back: |
    import heapq

    def dijkstra(graph, start_vertex):
        heap = [(0, start_vertex)]
        distances = {vertex: float('inf') for vertex in graph}
        distances[start_vertex] = 0

        while heap:
            curr_dist, vertex = heapq.heappop(heap)
            if curr_dist > distances[vertex]:
                continue
            for neighbor, weight in graph[vertex]:
                distance = curr_dist + weight
                if distance < distances[neighbor]:
                    distances[neighbor] = distance
                    heapq.heappush(heap, (distance, neighbor))

        return distances
  time-complexity: O((V + E) log V), due to heap operations.
  space-complexity: O(V), space for storing distances.
  description: |
    Use Cases:
      - Find the shortest path in weighted graphs.
    Paradigms:
      - Greedy Algorithm

- front: 'Kruskal’s Algorithm (Minimum Spanning Tree)'
  back: |
    class UnionFind:
        def __init__(self, size):
            self.parent = list(range(size))
            self.rank = [1] * size

        def find(self, node):
            if self.parent[node] != node:
                self.parent[node] = self.find(self.parent[node])
            return self.parent[node]

        def union(self, u, v):
            root1, root2 = self.find(u), self.find(v)
            if root1 != root2:
                if self.rank[root1] > self.rank[root2]:
                    self.parent[root2] = root1
                elif self.rank[root1] < self.rank[root2]:
                    self.parent[root1] = root2
                else:
                    self.parent[root2] = root1
                    self.rank[root1] += 1

    def kruskal(graph, num_nodes):
        edges = sorted(graph, key = lambda edge: edge[2])  # Sort by weight
        uf = UnionFind(num_nodes)
        mst = []

        for u, v, weight in edges:
            if uf.find(u) != uf.find(v):
                uf.union(u, v)
                mst.append((u, v, weight))

        return mst
  time-complexity: O(E log E), where E is the number of edges.
  space-complexity: O(V), space for the Union-Find structure.
  description: |
    Use Cases:
      - Finding Minimum Spanning Tree in a graph.
    Paradigms:
      - Greedy Algorithm

- front: 'Heap Sort'
  back: |
    import heapq

    def heap_sort(arr):
        heapq.heapify(arr)
        return [heapq.heappop(arr) for _ in range(len(arr))]
  time-complexity: O(n log n), where n is the number of elements.
  space-complexity: O(n), due to the heap structure.
  description: |
    Paradigms:
      - Heap-based Sorting
      - Selection-based Sorting

- front: 'Topological Sorting (Kahn’s Algorithm)'
  back: |
    from collections import deque

    def topological_sort(graph):
        in_degree = {vertex: 0 for vertex in graph}
        for vertex in graph:
            for neighbor in graph[vertex]:
                in_degree[neighbor] += 1

        que = deque([vertex for vertex in in_degree if in_degree[vertex] == 0])
        result = []

        while que:
            vertex = que.popleft()
            result.append(vertex)
            for neighbor in graph[vertex]:
                in_degree[neighbor] -= 1
                if in_degree[neighbor] == 0:
                    que.append(neighbor)
        # Return empty if cycle exists
        return result if len(result) == len(graph) else []
  time-complexity: O(V + E), where V is the number of vertices and E is the number of edges.
  space-complexity: O(V), space for storing in-degree and the queue.
  description: |
    Paradigms:
      - Graph Traversal
      - FIFO

- front: 'Merge Sort'
  back: |
    def merge_sort(arr):
        if len(arr) <= 1:
            return arr
        mid = len(arr) // 2
        left = merge_sort(arr[:mid])
        right = merge_sort(arr[mid:])
        return sorted(left + right)
  time-complexity: O(n log n), where n is the number of elements.
  space-complexity: O(n), due to the space for the sorted array.
  description: |
    Paradigms:
      - Divide and Conquer
      - Sorting

- front: 'Quicksort (Randomized)'
  back: |
    from random import randint

    def quicksort(arr):
        pivot = arr[randint(0, len(arr) - 1)]
        left = [x for x in arr if x < pivot]
        mid = [x for x in arr if x == pivot]
        right = [x for x in arr if x > pivot]
        return quicksort(left) + middle + quicksort(right)
  time-complexity: O(n^2) in the worst case.
  space-complexity: O(n) due to recursion stack.
  description: |
    Paradigms:
      - Divide and Conquer
      - Randomization
      - Sorting

- front: 'Breadth First Traversal (Tree, Level Order)'
  back: |
    from collections import deque

    def bfs(root):
        que = deque([root])
        while que:
            node = que.popleft()
            print(node.val)
            if node.left:
                que.append(node.left)
            if node.right:
                que.append(node.right)
  time-complexity: O(n), where n is the number of nodes.
  space-complexity: O(n), space for the queue.
  description: |
    Paradigms:
      - Tree Traversal
      - Level Order Traversal
      - FIFO

- front: 'Depth First Traversal: Recursive, Tree, Preorder'
  back: |
    def dfs_preorder(root):
        if root:
            print(root.val)
            dfs_preorder(root.left)
            dfs_preorder(root.right)
  time-complexity: O(n), where n is the number of nodes.
  space-complexity: O(h), where h is the height of the tree (due to recursion stack).
  description: |
    Paradigms:
      - Tree Traversal
      - Recursion
      - LIFO

- front: 'Floyd-Warshall'
  back: |
    def floyd_warshall(graph):
        dist = {ov: {dv: float('inf') for dv in graph} for ov in graph}
        
        # Distance from a vertex to itself is 0
        for vertex in graph:
            dist[vertex][vertex] = 0
            
        for ov, neighbors in graph.items():
            for dv, weight in neighbors.items():
                dist[ov][dv] = weight

        for mv in graph:
            for ov in graph:
                for dv in graph:
                    if dist[ov][dv] > dist[ov][mv] + dist[mv][dv]:
                        dist[ov][dv] = dist[ov][mv] + dist[mv][dv]
        return dist
  time-complexity: O(V^3), where V is the number of vertices in the graph.
  space-complexity: O(V^2), due to the 2D matrix for distances.
  description: |
    Use Cases:
      - Find the shortest path between all pairs of vertices in a graph.
      - Can be used for detecting negative cycles.
    Paradigms:
      - Dynamic Programming

- front: 'Bellman-Ford'
  back: |
    def bellman_ford(graph, start_vertex):
        distances = {vertex: float('inf') for vertex in graph}
        distances[start_vertex] = 0

        for _ in range(len(graph) - 1):
            for u in graph:
                for v, weight in graph[u].items():
                    if distances[u] + weight < distances[v]:
                        distances[v] = distances[u] + weight

        # Detect negative cycles
        for u in graph:
            for v, weight in graph[u].items():
                if distances[u] + weight < distances[v]:
                    raise ValueError('Graph contains a negative weight cycle')

        return distances
  time-complexity: O(V * E), where V is the number of vertices and E is the number of edges.
  space-complexity: O(V), for storing the distance of each vertex.
  description: |
    Use Cases:
      - Find the shortest path from a single source to all vertices in a graph.
      - Can handle graphs with negative edge weights.
      - Detect negative weight cycles in a graph.
    Paradigms:
      - Dynamic Programming
