- front: 'Binary Search'
  back: |
    def binary_search(arr, target) -> int:
        l, r = 0, len(arr) - 1
        
        while l <= r:
            m = l + (r - l) // 2
            
            if arr[m] > target:
                r = m - 1
            elif arr[m] < target:
                l = m + 1
            else:
                return m
        
        return -1
  time-complexity: O(log n)
  space-complexity: O(1)
  description: |
    Paradigms:
      - Divide and Conquer

- front: 'Trie: Insert Word'
  back: |
    def insert_word(word):
        ptr = self.root
        for letter in word:
            ptr = ptr.children.setdefault(letter, TrieNode())
        ptr.final_node = True
  time-complexity: O(n), where n is the length of the word.
  space-complexity: O(n) for a single word, where n is the word's length.
  description: |
    Paradigms:
      - Tree-Based Search
      - Prefix Tree
      - Trie

- front: 'Trie: Search Word'
  back: |
    def search_word(word) -> bool:
        ptr = self.root
        for letter in word:
            if letter not in ptr.children:
                return False
            ptr = ptr.children[letter]
        return ptr.final_node
  time-complexity: O(n), where n is the length of the word.
  space-complexity: O(1) for a single word, where n is the word's length.
  description: |
    Paradigms:
      - Tree-Based Search
      - Prefix Tree
      - Trie

- front: 'Trie: Search Prefix'
  back: |
    def search_prefix(prefix) -> bool:
        ptr = self.root
        for letter in prefix:
            if letter not in ptr.children:
                return False
            ptr = ptr.children[letter]
        return True
  time-complexity: O(n), where n is the length of the prefix.
  space-complexity: O(1) for a single word, where n is the word's length.
  description: |
    Paradigms:
      - Tree-Based Search
      - Prefix Tree
      - Trie

- front: 'Trie: Delete Word'
  back: |
    def delete_word(word):
        def _delete(ptr, word, index) -> bool:
            if index == len(word):
                if not ptr.final_node:
                    return False
                ptr.final_node = False
                # If no children, delete.
                return len(ptr.children) == 0
            letter = word[index]
            if letter not in ptr.children:
                return False
            deletable = _delete(ptr.children[letter], word, index + 1)
            if deletable:
                del ptr.children[letter]
                return not ptr.final_node and len(ptr.children) == 0
            return False
        
        _delete(self.root, word, 0)
  time-complexity: O(n), where n is the length of the word.
  space-complexity: O(n), where h is the height of the tree (due to recursion stack)
  description: |
    Paradigms:
      - Tree-Based Search
      - Prefix Tree
      - Trie

- front: 'Trie: Autocomplete'
  back: |
    def autocomplete(prefix) -> list:
        ptr = self.root
        for letter in prefix:
            if letter not in ptr.children:
                # No words with this prefix
                return []
            ptr = ptr.children[letter]

        # Perform DFS to collect all words from this ptr onward
        def dfs(ptr, word):
            matches = []
            if ptr.final_node:
                matches.append(word)
            for letter, child_node in ptr.children.items():
                matches.extend(dfs(child_node, word + letter))
            return matches

        return dfs(ptr, prefix)
  time-complexity: O(n), where n is the length of the prefix.
  space-complexity: O(w), where w is the number of words in the dictionary.
  description: |
    Paradigms:
      - Tree-Based Search
      - Prefix Tree
      - Trie

- front: 'Singly-Linked List: Insert at the head'
  back: |
    def insert_at_head(head, val) -> ListNode:
        new_node = ListNode(val)
        if not head:
            return new_node
        new_node.next = head
        return new_node
  time-complexity: O(1), constant time.
  space-complexity: O(1).
  description: |
    Paradigms:
      - Linear Data Structures
      - Pointer Manipulation
      - Linked List

- front: 'Singly-Linked List: Insert at the Tail'
  back: |
    def insert_at_tail(head, val) -> ListNode:
        new_node = ListNode(val)
        if not head:
            return new_node
        ptr = head
        while ptr.next:
            ptr = ptr.next
        ptr.next = new_node
        return head
  time-complexity: O(n), where n is the number of nodes.
  space-complexity: O(1).
  description: |
    Paradigms:
      - Linear Data Structures
      - Pointer Manipulation
      - Linked List

- front: 'Singly-Linked List: Delete Node'
  back: |
    def delete_node(head, val) -> ListNode:
        if head.val == val:
            return head.next
        ptr = head
        while ptr and ptr.next:
            if ptr.next.val == val:
                ptr.next = ptr.next.next
                break
            ptr = ptr.next
        return head
  time-complexity: O(n), where n is the number of nodes.
  space-complexity: O(1).
  description: |
    Paradigms:
      - Linear Data Structures
      - Pointer Manipulation
      - Linked List

- front: 'Singly-Linked List: Insert at index'
  back: |
    def insert_at_index(head, index, val) -> ListNode:
        if not head or index < 0:
          return head
        new_node = ListNode(val)
        if index == 0:
            new_node.next = head
            return new_node
        ptr = head
        for i in range(index - 1):
            if not ptr:
                return head
            ptr = ptr.next
        if ptr:
            new_node.next = ptr.next
            ptr.next = new_node
        return head
  time-complexity: O(n), where n is the number of nodes.
  space-complexity: O(1).
  description: |
    Paradigms:
      - Linear Data Structures
      - Pointer Manipulation
      - Linked List

- front: 'Singly-Linked List: Delete at index'
  back: |
    def delete_at_index(head, index) -> ListNode:
        if not head or index < 0:
            return head
        if index == 0:
            return head.next
        ptr = head
        for i in range(index - 1):
            if not ptr:
                return head
            ptr = ptr.next
        if ptr and ptr.next:
            ptr.next = ptr.next.next
        return head
  time-complexity: O(n), where n is the number of nodes.
  space-complexity: O(1).
  description: |
    Paradigms:
      - Linear Data Structures
      - Pointer Manipulation
      - Linked List

- front: 'Singly-Linked List: Merge sorted list'
  back: |
    def merge_sorted_lists(l1, l2) -> ListNode:
        dummy = ListNode()
        ptr = dummy
        while l1 and l2:
            if l1.val < l2.val:
                ptr.next = l1
                l1 = l1.next
            else:
                ptr.next = l2
                l2 = l2.next
            ptr = ptr.next
        ptr.next = l1 if l1 else l2
        return dummy.next
  time-complexity: O(n + m), where n and m are the lengths of the two lists.
  space-complexity: O(1) for all operations except reverse_list.
  description: |
    Paradigms:
      - Linear Data Structures
      - Pointer Manipulation
      - Linked List

- front: 'Singly-Linked List: Reverse List'
  back: |
    def reverse_list(head) -> ListNode:
        l = None
        m = head
        r = None

        while m:
            r = m.next
            m.next = l
            l = m
            m = r
        
        return l
  time-complexity: O(n), where n is the number of nodes.
  space-complexity: O(1).
  description: |
    Paradigms:
      - Linear Data Structures
      - Pointer Manipulation
      - Linked List

- front: 'Singly-Linked List: Detect cycle'
  back: |
    def detect_cycle(head) -> bool:
        sptr = head
        fptr = head
        
        while fptr and fptr.next:
            sptr = sptr.next
            fptr = fptr.next.next
            if sptr == fptr:
                return True
        return False
  time-complexity: O(n), where n is the number of nodes.
  space-complexity: O(1).
  description: |
    Paradigms:
      - Linear Data Structures
      - Pointer Manipulation
      - Linked List

- front: 'Breadth First Search on Graph'
  back: |
    from collections import deque

    def bfs(graph, start_vertex):
        visited = set()
        que = deque([start_vertex])

        while que:
            vertex = que.popleft()
            if vertex not in visited:
                visited.add(vertex)
                print(vertex)
                que.extend(graph.get(vertex, []))
  time-complexity: O(V + E), where V is the number of vertices and E is the number of edges.
  space-complexity: O(V), space for visited nodes and the queue.
  description: |
    Use Cases:
      - Find shortest path in unweighted graphs.
      - Find all reachable nodes from a source node.
    Paradigms:
      - Graph Traversal
      - Queue-Based Search
      - FIFO

- front: 'Depth First Search on Graph: Iterative'
  back: |
    def dfs(graph, start_vertex):
        visited = set()
        stack = [start_vertex]

        while stack:
            vertex = stack.pop()
            if vertex not in visited:
                visited.add(vertex)
                print(vertex)
                stack.extend(graph.get(vertex, []))
  time-complexity: O(V + E), where V is the number of vertices and E is the number of edges.
  space-complexity: O(V), space for visited nodes and the stack.
  description: |
    Use Cases:
      - Find connected components.
      - Traversal for exploring all nodes.
    Paradigms:
      - Graph Traversal
      - Stack-Based Search
      - LIFO

- front: 'Depth First Search on Graph: Recursive Graph'
  back: |
    def dfs(graph, start_vertex, visited = None):
        if visited is None:
            visited = set()
        visited.add(start_vertex)
        print(start_vertex)

        for neighbor in graph.get(start_vertex, []):
            if neighbor not in visited:
                dfs(graph, neighbor, visited)
  time-complexity: O(V + E), where V is the number of vertices and E is the number of edges.
  space-complexity: O(V), due to the recursion stack.
  description: |
    Use Cases: 
      - Explore all nodes in a graph recursively.
    Paradigms:
      - Graph traversal
      - Recursion

- front: 'Dijkstra’s Algorithm (Shortest Path)'
  back: |
    import heapq

    def dijkstra(graph, start_vertex):
        heap = [(0, start_vertex)]
        dist = {vertex: float('inf') for vertex in graph}
        dist[start_vertex] = 0

        while heap:
            curr_dist, vertex = heapq.heappop(heap)
            if curr_dist > dist[vertex]:
                continue
            for neighbor, weight in graph[vertex]:
                distance = curr_dist + weight
                if distance < dist[neighbor]:
                    dist[neighbor] = distance
                    heapq.heappush(heap, (distance, neighbor))

        return dist
  time-complexity: O((V + E) log V), due to heap operations.
  space-complexity: O(V), space for storing distances.
  description: |
    Use Cases:
      - Find the shortest path in weighted graphs.
    Paradigms:
      - Greedy Algorithm

- front: 'Kruskal’s Algorithm (Minimum Spanning Tree)'
  back: |
    class UnionFind:
        def __init__(self, size):
            self.parent = list(range(size))
            # Initialize all ranks to 1
            self.rank = [1] * size

        def find(self, node):
            if self.parent[node] != node:
                # Path compression
                self.parent[node] = self.find(self.parent[node])
            return self.parent[node]

        def union(self, u, v):
            root1, root2 = self.find(u), self.find(v)
            if root1 != root2:
                if self.rank[root1] > self.rank[root2]:
                    self.parent[root2] = root1
                elif self.rank[root1] < self.rank[root2]:
                    self.parent[root1] = root2
                else:
                    self.parent[root2] = root1
                    # Increase rank only when merging equal ranks
                    self.rank[root1] += 1

    def kruskal(graph, num_nodes):
        # Sort edges by weight
        edges = sorted(graph, key = lambda edge: edge[2])
        uf = UnionFind(num_nodes)
        mst = []

        for u, v, weight in edges:
            if uf.find(u) != uf.find(v):
                uf.union(u, v)
                mst.append((u, v, weight))

        return mst
  time-complexity: O(E log E), where E is the number of edges.
  space-complexity: O(V), space for the Union-Find structure.
  description: |
    Use Cases:
      - Finding Minimum Spanning Tree in a graph.
    Paradigms:
      - Greedy Algorithm

- front: 'Heap Sort'
  back: |
    import heapq

    def heap_sort(arr):
        heapq.heapify(arr)
        return [heapq.heappop(arr) for _ in range(len(arr))]
  time-complexity: O(n log n), where n is the number of elements.
  space-complexity: O(n), due to the heap structure.
  description: |
    Paradigms:
      - Heap-based Sorting
      - Selection-based Sorting

- front: 'Kahn’s Algorithm: Topological Sort'
  back: |
    from collections import deque

    def topological_sort(graph):
        in_degree = {vertex: 0 for vertex in graph}
        for vertex in graph:
            for neighbor in graph[vertex]:
                in_degree[neighbor] += 1

        que = deque([vertex for vertex in in_degree 
                    if in_degree[vertex] == 0])
        result = []

        while que:
            vertex = que.popleft()
            result.append(vertex)
            for neighbor in graph[vertex]:
                in_degree[neighbor] -= 1
                if in_degree[neighbor] == 0:
                    que.append(neighbor)
        # Return empty if cycle exists
        return result if len(result) == len(graph) else []
  time-complexity: O(V + E), where V is the number of vertices and E is the number of edges.
  space-complexity: O(V), space for storing in-degree and the queue.
  description: |
    Paradigms:
      - Graph Traversal
      - FIFO

- front: 'Merge Sort'
  back: |
    def merge_sort(arr):
        if len(arr) <= 1:
            return arr
        mid = len(arr) // 2
        left = merge_sort(arr[:mid])
        right = merge_sort(arr[mid:])
        return sorted(left + right)
  time-complexity: O(n log n), where n is the number of elements.
  space-complexity: O(n), due to the space for the sorted array.
  description: |
    Paradigms:
      - Divide and Conquer
      - Sorting

- front: 'Quicksort: Randomized'
  back: |
    def quicksort(arr):
        pivot = random.choice(arr)
        left = [x for x in arr if x < pivot]
        mid = [x for x in arr if x == pivot]
        right = [x for x in arr if x > pivot]
        return quicksort(left) + mid + quicksort(right)
  time-complexity: O(n^2) in the worst case.
  space-complexity: O(n) due to recursion stack.
  description: |
    Paradigms:
      - Divide and Conquer
      - Randomization
      - Sorting

- front: 'Breadth First Traversal on Tree: Level Order'
  back: |
    from collections import deque

    def bfs(root):
        que = deque([root])
        while que:
            node = que.popleft()
            print(node.val)
            if node.left:
                que.append(node.left)
            if node.right:
                que.append(node.right)
  time-complexity: O(n), where n is the number of nodes.
  space-complexity: O(n), space for the queue.
  description: |
    Paradigms:
      - Tree Traversal
      - Level Order Traversal
      - FIFO

- front: 'Depth First Traversal on Tree: Recursive, Preorder'
  back: |
    def dfs_preorder(root):
        if root:
            print(root.val)
            dfs_preorder(root.left)
            dfs_preorder(root.right)
  time-complexity: O(n), where n is the number of nodes.
  space-complexity: O(h), where h is the height of the tree (due to recursion stack).
  description: |
    Paradigms:
      - Tree Traversal
      - Recursion
      - LIFO

- front: 'Floyd-Warshall: All-Pairs Shortest Path'
  back: |
    def floyd_warshall(graph):
        dist = {ov: {dv: float('inf') for dv in graph} for ov in graph}
        
        # Distance from a vertex to itself is 0
        for vertex in graph:
            dist[vertex][vertex] = 0
            
        for ov, neighbors in graph.items():
            for dv, weight in neighbors.items():
                dist[ov][dv] = weight

        for mv in graph:
            for ov in graph:
                for dv in graph:
                    if dist[ov][dv] > dist[ov][mv] + dist[mv][dv]:
                        dist[ov][dv] = dist[ov][mv] + dist[mv][dv]
        return dist
  time-complexity: O(V^3), where V is the number of vertices in the graph.
  space-complexity: O(V^2), due to the 2D matrix for distances.
  description: |
    Use Cases:
      - Find the shortest path between all pairs of vertices in a graph.
      - Can be used for detecting negative cycles.
    Paradigms:
      - Dynamic Programming

- front: 'Bellman-Ford: Single-Source Shortest Path'
  back: |
    def bellman_ford(graph, start_vertex):
        dist = {vertex: float('inf') for vertex in graph}
        dist[start_vertex] = 0

        for _ in range(len(graph) - 1):
            for ov, neighbor in graph.items():
                for dv, weight in neighbor.items():
                    if dist[ov] + weight < dist[dv]:
                        dist[dv] = dist[ov] + weight

        # Detect negative cycles
        for ov, neighbor in graph.items():
            for dv, weight in neighbor.items():
                if dist[ov] + weight < dist[dv]:
                    raise ValueError('Negative weight cycle detected')

        return dist
  time-complexity: O(V * E), where V is the number of vertices and E is the number of edges.
  space-complexity: O(V), for storing the distance of each vertex.
  description: |
    Use Cases:
      - Find the shortest path from a single source to all vertices in a graph.
      - Can handle graphs with negative edge weights.
      - Detect negative weight cycles in a graph.
    Paradigms:
      - Dynamic Programming

- front: 'Island Counting: DFS, Recursive'
  back: |
    def count_islands(grid):
      if not grid: return 0
      rows, cols = len(grid), len(grid[0])

      def dfs(r, c):
          if 0 <= r < rows and 0 <= c < cols and grid[r][c] == "1":
              grid[r][c] = "0"  # Mark visited
              for dr, dc in [(1,0), (-1,0), (0,1), (0,-1)]:  # 4 directions
                  dfs(r + dr, c + dc)

      islands = 0
      for r in range(rows):
          for c in range(cols):
              if grid[r][c] == "1":
                  dfs(r, c)
                  islands += 1
      return islands
  time-complexity: O(n*m)
  space-complexity: O(n*m)
  description: |
    The algorithm iterates through the grid, and when a "1" (land) is found, it performs a depth-first search (DFS) to mark all connected land cells as visited (by changing them to "0"). This effectively counts one island and prevents recounting. The process repeats for each unvisited "1".
    Paradigms:
      - Graph traversal (DFS-based)
      - Recursion
      - Flood fill algorithm

- front: 'Island Counting: BFS'
  back: |
    from collections import deque

    def count_islands(grid):
        if not grid:
            return 0

        rows, cols = len(grid), len(grid[0])
        islands = 0

        for r in range(rows):
            for c in range(cols):
                if grid[r][c] == "1":
                    islands += 1
                    grid[r][c] = "0"  # Mark the cell as visited.
                    queue = deque([(r, c)])
                    
                    # Use BFS to visit all connected "1"s.
                    while queue:
                        cur_r, cur_c = queue.popleft()
                        for dr, dc in [(1, 0), (-1, 0), (0, 1), (0, -1)]:
                            new_r, new_c = cur_r + dr, cur_c + dc
                            if 0 <= new_r < rows and 0 <= new_c < cols and grid[new_r][new_c] == "1":
                                grid[new_r][new_c] = "0"
                                queue.append((new_r, new_c))
        return islands

  time-complexity:
  space-complexity:
  description: |

- front: 'Maze Solving: DFS'
  back: |
    def solveMaze(maze, start, end):
        rows, cols = len(maze), len(maze[0])
        # To keep track of the current path
        path = []

        def dfs(r, c):
            # Check if out-of-bounds or hit a wall or visited cell.
            if not (0 <= r < rows and 0 <= c < cols) or maze[r][c] != "0":
                return False

            # Mark the cell as part of the path and visited.
            path.append((r, c))
            # 'v' indicates visited
            maze[r][c] = "v"

            # Check if we've reached the destination.
            if (r, c) == end:
                return True

            # Explore all four directions.
            for dr, dc in [(1, 0), (-1, 0), (0, 1), (0, -1)]:
                if dfs(r + dr, c + dc):
                    return True

            # Backtrack if no path is found from the current cell.
            path.pop()
            return False

        if dfs(start[0], start[1]):
            # A valid path from start to end was found.
            return path
        else:
            # No path exists.
            return None

  time-complexity:
  space-complexity:
  description: |
